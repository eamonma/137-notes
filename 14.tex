\input{~/preamble.tex}

\usepackage{blindtext}


\usepackage{subfiles}

\sectionfont{\color{blue}\selectfont}
\subsectionfont{\color{green}\selectfont}

\newcommand{\eg}{\textbf{e.g.}~}
\newcommand{\abs}[1]{\left\lvert #1 \right\rvert}

\begin{document}
\newtheorem{theorem}{Theorem}[section]
\newtheorem*{theorem*}{Theorem}
\newtheorem{definition}{Definition}[section]
{\LARGE \textbf{Unit 13: Series}}
\thispagestyle{empty}
\tableofcontents
\newpage
\clearpage
\setcounter{page}{1}
\section{Power series: an example}
\eg I want to define a function with this equation: \[g(x) = \sum_{n = 1}^{\infty} \frac{x^n}{n3^n}\]
For which \(x \in \R\) is \(g(x)\) convergent? We can use the Ratio Test.
\begin{align*}
    \text{Call } a_n                                       & = \frac{x^n}{n3^n}                                                      \\
    L = \lim_{n\to\infty} \cfrac{\abs{a_{n+1}}}{\abs{a_n}} & = \cfrac{\abs{\cfrac{x^{n+1}}{(n+1) 3^{n+1}}}}{\abs{\cfrac{x^n}{n3^n}}} \\
                                                           & = \frac{\abs{x}}{3}
\end{align*}
\begin{itemize}
    \item If \(\abs{x} < 3\), then \(L = \frac{\abs{x}}{3} < 1\). By Ratio Test, \(g(x)\) is absolutely convergent.
    \item If \(\abs{x} > 3\), then \(L = \frac{\abs{x}}{3} > 1\). By Ratio test, \(g(x)\) is divergent.
\end{itemize}
We don't know what happens at \(x = -3\) or \(x = 3\) yet. \\
\begin{align*}
    g(3)  & = \sum_{n = 1}^{\infty} \frac{3^n}{n3^n} = \frac{1}{n}  = \infty \text{ (p-series with \DS{p = 1})} \\
    g(-3) & = \sum_{n = 1}^{\infty} \frac{(-3)^n}{n3^n} = \frac{(-1)^n}{n} \text{ convergent (by \textsc{ast})} \\
\end{align*}
Then, at \(x = -3\), \(g(x)\) is conditionally convergent, and \(3\), it is divergent. \\
To answer the original question, the domain of \(g = [-3, 3)\) = the \textsc{interval of convergence}. \(3\) = the \textsc{radius of convergence}.
\newpage



\section{Power series: the main theorem}
\subsection*{Motivation}
\begin{itemize}
    \item Polynomials are nice
    \item What about ``infinite polynomials''? \\
          \[f(x) = c_0 + c_1x + c_2x^2 + c_3x^3 + \dots\]
          \[\text{or} \quad f(x) = c_0 + c_1 (x - a) + c_2 (x - a)^2 + c_3 (x - a)^3 + \dots\]
    \item \eg: \begin{itemize}
              \item \(g(x) = \sum_{n = 1}^{\infty} \frac{x^n}{n3^n}\) has domain \([-3, 3)\)
              \item \(h(x) = \sum_{n = 0}^{\infty} x^n\) has domain \((-1, 1)\)
          \end{itemize}
\end{itemize}
\df{
    Let \(a \in \R\). \\
    A \underline{power series centered at \(a\)} is a function \(f\) defined by an equation like \begin{align*}
        f(x) = \sum_{n = 0}^{\infty} c_n(x-a)^n = c_0 + c_1(x - a) + c_2(x - a)^2 + \dots
    \end{align*}
    where \(c_0, c_1, c_2, \dots \in \R\).
}

\begin{center}
    Domain \(f = \{x \in \R ~ : ~ \text{teh series \(f(x)\) is convergent}\}\)
\end{center}
Note: \(a \in\) Domain \(f\) \\
Ultimate goal: write common functions as power series.
\thm{
    Let \(f(x) = \sum_{n = 0}^{\infty} c_n (x - a)^n\) be a power series centered at \(a \in \R\). \begin{enumerate}
        \item The domain of \(f\) is an interval centered at a: \begin{align*}
                   & (a - R, a + R) \quad (a - R, a + R] \quad \R    \\
                   & [a - R, a + R] \quad [a - R, a + R) \quad \{a\}
              \end{align*} \begin{itemize}
                  \item We call this domain the \underline{interval of convergence} (\textsc{ic}) of \(f\).
                  \item We call its radius the \underline{radius of convergence}. \(\quad 0 \leq R \leq \infty\)
              \end{itemize}
        \item \begin{itemize}
                  \item In the \textbf{interior} of the \textsc{ic}, the series is absolutely convergent.
                  \item In the \textbf{exterior} of the \textsc{ic}, the series is divergent.
                  \item At the endpoints (if any), anything may happen.
              \end{itemize}
        \item In the interior of the \textsc{ic}, power series can be ``treated like polynomials''. They can be added, multiplied, composed\dots \\
              In particular, they can be differentiated or integrated ``term by term'', and this does not change the radius of convergence.
    \end{enumerate}
}

\begin{alignat*}{2}
    f(x)                   & = \sum_{n = 0}^{\infty} c_n x^n             &  & = c_0 + c_1x + c_2x^2 + c_3x^3 + \dots                 \\
    f'(x)                  & = \sum_{n = 0}^{\infty} c_n n x^{n-1}       &  & = c_1 + 2c_2x + 3c_3x^2 + \dots                        \\
    \int_{0}^{x} {f(t)} dt & = \sum_{n = 0}^{\infty} \frac{x^{n+1}}{n+1} &  & = c_0x + c_1 \frac{x^2}{2} + c_2 \frac{x^3}{3} + \dots
\end{alignat*}

\textbf{Goals} \begin{enumerate}
    \item Write as many functions as possible as power series \\
          \(\longrightarrow\) Taylor series
    \item Use that to make limits, integrals, estimations, differential equations, physics,\dots easier.
\end{enumerate}

\newpage
\section{Taylor polynomials---the definition with the limit}
Goal: approximate functions with polynomials. \\
\(f\): function \\
\(a \in\) Domain \(f\) \\
\(P\): polynomial \\

I want \(P(x) \approx f(x)\) when \(x\) is close to \(a\). Example: the tangent line. But what is a ``good approximation near a''? \\
\(R\): "remainder" or "error" \(\quad R(x) = f(x) - P(x)\). I want \(R\) to be small. This means we need \(\lim_{x \to a} R(x) = 0 \) ``fast''. For instance, there are many lines with remainder \(0\), but the tangent line's remainder approaches \(0\) the ``fastest''. But how do we measure how fast the limit is? \\
We notice that the larger exponent polynomials approach \(0\) faster. We compare the remainder with powers of \(x\).
\df{
    Let \(f\) and \(g\) be continuous functions at \(0\). \\
    Let \(n \in \N\). \\
    We say that \underline{\(g\) is an approximation for \(f\) near \(0\) of order \(n\)} when
    \begin{align*}
        \lim_{x\to0} \frac{f(x) - g(x)}{x^n} = 0
    \end{align*}
}
This means that \(f(x) = g(x) + R(x)\) and as \(x \to 0\), \begin{align*}
    R(x) \to 0 \quad \text{faster than} \quad x^n \to 0
\end{align*}
\df{
    Let \(a \in \R\). Let \(f\) and \(g\) be continuous functions at \(a\). \\
    Let \(n \in \N\). \\
    We say that \underline{\(g\) is an approximation for \(f\) near \(a\) of order \(n\)} when
    \begin{align*}
        \lim_{x\to a} \frac{f(x) - g(x)}{(x-a)^n} = 0
    \end{align*}
}

\subsection*{First definition of Taylor polynomial}
\df{
    Let \(a \in \R\). \\
    Let \(f\) be a continuous function defined at and near \(a\). \\
    Let \(n \in \N\). \\
    The \underline{\(n\)-th Taylor polynoial for \(f\) at \(a\)} is a polynomial \(P_n\) \begin{itemize}
        \item \dots that is an approximation for \(f\) near \(a\) of order \(n\): \begin{align*}
                  \lim_{x\to a} \frac{f(x) - P_n(x)}{(x-a)^n} = 0
              \end{align*}
        \item with degree at most n
    \end{itemize}
}



\newpage
\section{Taylor polynomials---the definition with the derivatives}
\df{
    A function \(f\) is called \dots \begin{itemize}
        \item \(C^0\) when \(f\) is continuous
        \item \(C^1\) when \(f'\) exists and is continuous
        \item \(C^2\) when \(f'\) and \(f''\) exist and are continuous
        \item \dots
        \item \(C^n\) when \(f', f'', \dots, f^{(n)}\) exist and are continuous
        \item \(C^\infty\) when all derivatives exist (and are continuous)
    \end{itemize}
}
For now, assume \(f\) and \(g\) are \(C^\infty\). Can I transform the condition \begin{align*}
    \lim_{x\to a} \frac{f(x) - g(x)}{(x-a)^n} = 0
\end{align*}
into a condition about their derivatives?

\begin{itemize}
    \item Call \DS{L = \lim_{x\to a} \frac{f(x) - g(x)}{(x-a)^n}} \begin{itemize}
              \item If \(f(a) - g(a) \neq 0\), then ``\(L = \frac{\text{not } 0}{0} = \pm \infty\)''.
              \item So, assume \(f(a) = g(a)\). We get \(0/0\). Use L'hôpital's.
          \end{itemize}
    \item \DS{L \stackrel{*}{=} \lim_{x\to a} \frac{f'(x) - g'(x)}{n(x-a)^{n-1}}} \begin{itemize}
              \item If \(f'(a) - g'(a) \neq 0\), then ``\(L = \frac{\text{not } 0}{0} = \pm \infty\)''
              \item So, assume \(f'(a) = g'(a)\). We get \(0/0\). Use L'hôpital's.
          \end{itemize}
    \item \DS{L \stackrel{*}{=} \lim_{x\to a} \frac{f''(x) - g''(x)}{n(n-1)(x-a)^{n-2}} \dots}
    \item After using L'hôpital's rule \(n\) times, we get \begin{align*}
              L \stackrel{*}{=} \lim_{x\to a} \frac{f^{(n)}(x) - g^{(n)}(x)}{n!} = \frac{f^{(n)}(a) - g^{(n)}(a)}{n!} \qquad \text{since the derivatives are continuous}
          \end{align*}
\end{itemize}
\begin{align*}
    L = 0 \Longleftrightarrow \begin{cases}
        f(a)         & = g(a)         \\
        f'(a)        & = g'(a)        \\
        \dots                         \\
        f^{(n-1)}(a) & = g^{(n-1)}(a) \\
        f^{(n)}(a)   & = g^{(n)}(a)   \\
    \end{cases}
\end{align*}
I have used that \(f\) and \(g\) were \(C^n\).

\thm{
    Let \(a \in \R\). Let \(n \in \N\). \\
    Let \(f\) and \(g\) be \(C^n\) functions at \(a\). \\
    The following are equivalent: \begin{enumerate}
        \item \DS{\lim_{x\to a} \frac{f(x) - g(x)}{(x-a)^n} = 0} \\ (``\(g\) is a good approximation for \(f\) near \(a\)'')
        \item \DS{f(a) = g(a), f'(a) = g'(a), \dots, f^{n}(a) = g^{n}(a)} \\ (``\(g\) and \(f\) have the same first few derivatives at \(a\)'')
    \end{enumerate}
}
This proof could be made more formal by using induction.

\df{
    Let \(a \in \R\). \\
    Let \(n \in \N\). \\
    Let \(f\) be a \(C^n\) function at \(a\). \\
    The \underline{\(n\)-th Taylor polynomial for \(f\) at \(a\)} is \begin{itemize}
        \item a polynomial \(P_n\) such that
        \item \(P_n(a) = f(a), P_n'(a) = f'(a), \dots P_n^{(n)}(a) = f^{(n)}(a)\)
        \item with degree at most \(n\).
    \end{itemize}
}

This definition is more useful that the original, limit definition for constructing these polynomials. However, we should keep the original definition in mind---it tells us why Taylor polynomials make good approximations. \\
Notice that this is not a completely new idea: the first Taylor polynomial according to this definition is \(y = P_1(x)\), or the tangent line.



\newpage
\section{Taylor polynomials---the formula}
\begin{center}
    \fbox{
        \parbox{45em}{
            \textbf{Recall:} \\
            The \(n\)-th \underline{Taylor polynomial \(P_n\)} for the function \(f\) at \(a \in \R\)\dots \begin{itemize}
                \item is an approximation for \(f\) near \(a\) of order \(n\): \begin{align*}
                          \lim_{x\to a} \frac{f(x) - P_n(x)}{(x-a)^n} = 0
                      \end{align*}
                \item equivalently, has same value and first \(n\) derivatives as \(f\) at \(a\): \begin{align*}
                          P_n(a) = f(a), ~ P_n'(a) = f'(a), ~ \dots, ~ P_n^{(n)}(a) = f^{(n)}(a)
                      \end{align*}
            \end{itemize}
        }
    }
\end{center}
For simplicity, begin with: \\
\textbf{Case \(a = 0\)} \\
\begin{align*}
    P_n(x) = c_0 + c_1x + c_2x^2 + c_3x^3 + \dots + c_n x^n
\end{align*} \begin{align*}
    P_n(0)       & = f(0)       \\
    P_n'(0)      & = f'(0)      \\
    P_n''(0)     & = f''(0)     \\
    \dots                       \\
    P_n^{(n)}(0) & = f^{(n)}(0)
\end{align*}
So, \begin{align*}
    P_n^{(k)}(0) & = k! \cdot c_k = f^{(k)} \\
    c_k = \frac{f^{(k)}(0)}{k!}             \\
    \boxed{P_n(x) = \sum_{k = 0}^{n} \frac{f^{(k)}(0)}{k!} x^k}
\end{align*}
Now, how do we \\
\textbf{Generalize \(a\)?}
Instead of \begin{align*}
    P_n(x) = c_0 + c_1x + c_2x^2 + c_3x^3 + \dots + c_n x^n
\end{align*}
write \begin{align*}
    P_n(x) = b_0 + b_1(x - a) + b_2(x - a)^2 + b_3(x - a)^3 + \dots + b_n (x - a)^n
\end{align*}
We obtain \begin{align*}
    \boxed{P_n(x) = \sum_{k = 0}^{n} \frac{f^{(k)}(a)}{k!} (x-a)^k}
\end{align*}
\df{
    \textbf{Third definition of Taylor polynomial}
    \begin{itemize}
        \item Let \(a \in \R\)
        \item Let \(n \in \N\)
        \item Let \(f\) be a \(C^n\) function at \(a\).
    \end{itemize}
    The \underline{\(n\)-th Taylor polynomial} for \(f\) at \(a\) is \begin{align*}
        P_n(x) = \sum_{k = 0}^{n} \frac{f^{(k)}(a)}{k!} (x-a)^k
    \end{align*}
}
Notes: \begin{itemize}
    \item degree \(P_n \leq n\)
    \item The Taylor polynomials of a function are unique
\end{itemize}
We can see that the higher degree the Taylor polynomial is, the more accurate the approximation.
\df{
    \textbf{Taylor series}
    \begin{itemize}
        \item Let \(a \in \R\)
        \item Let \(f\) be a \(C^\infty\) function at \(a\)
    \end{itemize}
    The \underline{Taylor series} for \(f\) at \(a\) is the power series \begin{align*}
        S(x) = \sum_{k = 0}^{\infty} \frac{f^{(k)}(a)}{k!} (x - a)^k
    \end{align*}
}
Equivalently, \(\forall k \in \N,~ S^{(k)}(a) = f^{(k)}(a)\) \\
Ideal case: \(f(x) = S(x)\); we call such functions \emph{analytic}. \\
Note: ``Maclaurin series'' means ``Taylor series at \(0\)''.
\end{document}